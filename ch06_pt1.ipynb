{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장 : 텍스트와 시퀀스를 위한 딥러닝 *Part 1*\n",
    "\n",
    "#### 구성\n",
    "* 텍스트 데이터 다루기\n",
    "* 순환 신경망 이해하기\n",
    "* 순환 신경망의 고급 사용법\n",
    "* 컨브넷을 이용한 시퀀스 처리\n",
    "\n",
    "\n",
    "\n",
    "#### 이 장에서 다룰 핵심 내용 \n",
    "* 텍스트 데이터를 유용한 형태로 전처리 하는 방법\n",
    "* 순환신경망을 사용하는 방법\n",
    "* 1D 컨브넷을 사용한 데이터 처리\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*텍스트 (단어의 시퀀스 또는 문자의 시퀀스), 시계열 또는 일반적인 시퀀스 데이터를 처리할 수 있는 딥러닝 모델, **순환 신경망(recurrent neural network)**, **1D 컨브넷 (1D Convnet)** 을 살펴보겠습니다.*\n",
    "* 문서 분류나 시계열 분류\n",
    "* 시계열 비교\n",
    "* 시퀀스-투-시퀀스 학습 (ex. 영어 문장을 프랑스 어로 변환하기)\n",
    "* 감성 분석 (트윗이나 영화 리뷰가 긍정적인지 부정적인지 분류하기)\n",
    "* 시계열 예측 (최근 날씨 데이터가 주어졌을 때 향후 날씨를 예측하기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 텍스트 데이터 다루기\n",
    "\n",
    "텍스트는 가장 흔한 시퀀스 형태의 데이터이다. 보통 단어 수준으로 작업하는 경우가 많다. 딥러닝 모델은 수치형 텐서만 다룰 수 있으므로, 텍스트를 수치형 텐서로 변환하는 **텍스트 벡터화** 과정을 거쳐야 합니다. 이에는 여러가지 방식이 있습니다. \n",
    "* 텍스트를 단어로 나누고 각 단어를 하나의 벡터로 변환합니다.\n",
    "* 텍스트를 문자로 나누고 각 문자를 하나의 벡터로 변환합니다.\n",
    "* 텍스트에서 단어나 문자의 n-gram을 추출하여 각 n-gram을 하나의 벡터로 변환합니다. n-gram은 연속된 단어나 문자의 그룹으로 텍스트에서 단어나 문자를 하나씩 이동하면서 추출합니다.\n",
    "\n",
    "토큰(token) : 텍스트를 나누는 단위 (단어, 문자, n-gram), 그리고 텍스트를 토큰으로 나누는 작업을 토큰화(tokenization)이라고 합니다.\n",
    "\n",
    "토큰과 벡터를 연결하는 방법은 여러가지가 있습니다.\n",
    "* 원-핫 인코딩 (One-hot encoding)\n",
    "* 토큰 임베딩 (Token embedding)\n",
    "\n",
    "\n",
    "### n-gram & BoW\n",
    "BoW가 **순서가 없는** 토큰화 방법이기 때문에 딥러닝 모델보다 얕은 학습방법의 언어 처리모델에 사용되는 경향이 있습니다. 시퀀스가 아니라 집합으로 간주되고 문장의 일반적인 구조가 사라지기 때문입니다. n-gram을 추출하는 것은 일종의 특성 공학 입니다. 딥러닝은 유연하지 못하고 불안정한 이런 방식을 계층적인 특성학습으로 대체합니다. (n-gram은 로지스틱 회기나 랜덤포레스트같은 얕은 학습방법의 텍스트 처리 모델을 사용할 때 강력하고 아주 유용한 특성 공학 입니다.)\n",
    "\n",
    "\n",
    "`The cat sat on the mat`\n",
    "\n",
    "\n",
    "* bag of 2-gram\n",
    "\n",
    "`{\"The\", \"The cat\", \"cat\", \"cat sat\", \"sat\", \"sat on\", \"on\", \"on the\", \"the\", \"the mat\", \"mat\"}`\n",
    "\n",
    "\n",
    "* bag of 3-gram\n",
    "\n",
    "`{\"The\", \"The cat\", \"cat\", \"cat sat\", \"The cat sat\", \"sat\", \"sat on\", \"on\", \"cat sat on\", \"on the\", \"the\", \"sat on the\", \"the mat\", \"mat\", \"on the mat\"}`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어와 문자의 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "token_index = {}\n",
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1\n",
    "            \n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros(shape=(len(samples), max_length, max(token_index.values()) + 1))\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i, j, index] = 1\n",
    "        \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "characters = string.printable\n",
    "token_index = dict(zip(characters, range(1, len(characters) + 1)))\n",
    "\n",
    "max_length = 50\n",
    "results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample):\n",
    "        index = token_index.get(character)\n",
    "        results[i, j, index] = 1\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에는 원본 텍스트 데이터를 단어 또는 문자 수준의 원-핫 인코딩으로 변환해 주는 유틸리티가 있습니다. 특수 문자를 제거하거나 빈도가 높은 N개의 단어만 선택하는 등 여러가지 중요한 기능들이 있기 때문에 이 유틸리티를 사용하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 1000)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원-핫 인코딩의 변종 중 하나는 **원-핫 해싱(One-hot Hashing)** 기법입니다. 이 방식은 어휘 사전에 있는 고유한 토큰의 수가 너무 커서 모두 다루기 어려울 때 사용합니다. 각 단어에 명시적으로 인덱스를 할당하고 이 인덱스를 딕셔너리에 저장하는 대신에 단어를 해싱하여 고정된 크기의 벡터로 변환합니다. 일반적으로 간단한 해싱 함수를 사용합니다. 이 방식의 주요 장점은 명시적인 단어 인덱스가 필요없기 때문에 메모리를 절약하고 온라인 방식으로 데이터를 인코딩할 수 있습니다. (**전체 데이터를 확인하지 않고 토큰을 생성할 수 있습니다.**) \n",
    "\n",
    "한 가지 단점은 해시 충돌(Hash Collision) 입니다. 2개의 단어가 같은 해시를 만들면 이를 바라보는 머신 러닝 모델은 단어 사이의 차이를 인식 하지 못합니다. 해싱 공간의 차원이 해싱될 고유 토큰의 전체 개수보다 훨씬 크면 해싱 출돌의 가능성이 줄어듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "dimensionality = 1000\n",
    "max_length     = 10\n",
    "\n",
    "results = np.zeros((len(samples), max_length, dimensionality))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = abs(hash(word)) % dimensionality\n",
    "        results[i, j, index] = 1\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 임베딩 사용하기\n",
    "\n",
    "단어와 벡터를 연관짓는 강력하고 인기있는 또 다른 방법은 **단어 임베딩** 이라는 밀집 단어 벡터를 사용하는 것 입니다. 원-핫 인코딩으로 만든 벡터는 *희소(Sparse)하고 (대부분 0 으로 체워짐) 고차원입니다. (어휘 사전에 있는 단어의 수와 차원이 같습니다.)* 반면 단어 임베딩은 **저차원의 실수형 벡터** 입니다. (희소 베터의 반대인 밀집 벡터) 단어 임베딩은 데이터로부터 학습됩니다. 보통 `256`차원, `512`차원 또는 큰 어휘사전을 다룰 때는 `1024` 차원의 단어 임베딩을 사용합니다. 반면에 원-핫 인코딩은 (2만 개의 토큰으로 이루어진 어휘 사전을 만드려면) `20,000`차원 또는 그 이상의 벡터일 경우가 많습니다. 따라서 단어 임베딩이 더 많은 정보를 적은 차원에 저장하빈다.\n",
    "\n",
    "* (문서 분류나 감성 예측 같은) 관심 대상인 문제와 함께 단어 임베딩을 학습합니다. 이런 경우에는 랜덤한 단어 벡터로 시작해서 신경망의 가중치를 학습하는 것과 같은 방식으로 벡터를 학습합니다.\n",
    "* 풀려는 문제가 아니고 다른 머신 러닝 작업에서 미리 계산된 단어 임베딩을 로드합니다. 이를 **사전 훈련된 단어 임베딩** 이라고 합니다.\n",
    "\n",
    "\n",
    "#### embedding 층을 사용하여 단어 임베딩 학습하기\n",
    "단어와 밀집 벡터를 연관 짓는 가장 간단한 방법은 렌덤하게 벡터를 선택하는 것 입니다. 이 방법은 임베딩 공간이 구조적이 않다는 것, accurate와 exact라는 단어는 대부분 문장에서 비슷한 의미로 사용되지만 완전히 다른 임베딩을 가지는데, 심층 신경망이 이런 임의의 구조적이지 않은 임베딩 공간을 이해하기는 어렵습니다.\n",
    "\n",
    "단어 벡터사이에 **좀 더 추상적이고 기하학적인 관계를 얻으려면** 단어사이에 있는 의미 관계를 반영해야 합니다. 단어 임베딩은 언어를 기하학적 공간에 매핑하는 것입니다.\n",
    "\n",
    "실제 단어 임베딩 공간에서 의미있는 기하학적 변환의 일반적인 예는 `gender` 벡터와 `plural` 벡터입니다. 그러나 특정 의미 관계의 중요성이 작업에 따라 다르기 때문에, 새로운 작업에는 새로운 임베딩을 학습하는 것이 타당합니다. 다행이 역전파를 사용하여 쉽게 만들 수 있고 케라스를 이용하면 더 쉽습니다. Embedding층의 가중치 학습하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(1000, 64)\n",
    "# Embedding 층은 적어도 2개의 매개변수를 받습니다. \n",
    "#### 가능한 토큰의 개수(여기서는 1000으로 단어 인덱스 최댓값 + 1)\n",
    "#### 임베딩 차원 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding층을 *정수 인덱스를 밀집 벡터로 매핑하는 딕셔너리로 이해하는 것*이 가장 좋습니다. 정수를 입력받아 내부 딕셔너리에서 이 정수에 연관된 벡터를 찾아 반환합니다. 딕셔너리 탐색은 효율적으로 수행해 냅니다.\n",
    "\n",
    "**단어 인덱스** &rightarrow; **임베딩 층** &rightarrow; **연관된 단어 벡터** \n",
    "\n",
    "임베딩 층은 2D 정수 텐서를 입력으로 받습니다. (각 샘플은 정수의 시퀀스 입니다.) `(32, 10)` 크기의 배치 (길이 10인 시퀀스의 32개로 이루어진 배치)나 `(64, 15)` 크기의 배치 (길이가 15인 시퀀스 64개로 이루어진 배치)를 주입할 수 있습니다. 배치에 있는 모든 시퀀스는 길이가 같아야 하므로 (하나의 텐서에 담아야 하기 때문에) 작은 길이의 시퀀스는 0으로 패딩되고 길이가 더 긴 시퀀스는 잘립니다.\n",
    "\n",
    "임베딩 층은 크기가 `(samples, sequence_length, embedding_dimensionality)` 인 3D 실수형 데이터를 반환합니다. 일너 3D텐서는 RNN 층이나 1D 합성곱 층에서 처리됩니다. 임베딩 층의 객체를 생성할 때 가중치는 다른 층과 마찬가지로 랜덤하게 초기화됩니다. 훈련을 하면서 이 단어 벡터는 역전파를 통해 점차 조정이 되어 이어지는 모델이 사용할 수 있더ㅗ록 임베딩 공간을 구성합니다. 훈련이 끝나면 임베딩 공간은 특정 문제에 특화된 구조를 가지게 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "\n",
    "max_features = 10000    # 특성으로 사용될 단어의 수\n",
    "maxlen       = 20       # 사용할 텍스트의 길이, 가장 빈번한 max_features개의 단어만 사용합니다.\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)\n",
    "\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen = maxlen)    # 리스트를 (sample, maxlen) 크기의 2D 정수 텐서로 변환합니다.\n",
    "x_test  = preprocessing.sequence.pad_sequences(x_test,  maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.6638 - acc: 0.6327 - val_loss: 0.6062 - val_acc: 0.7052\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.5331 - acc: 0.7536 - val_loss: 0.5204 - val_acc: 0.7326\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.4588 - acc: 0.7869 - val_loss: 0.4982 - val_acc: 0.7484\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.4218 - acc: 0.8077 - val_loss: 0.4910 - val_acc: 0.7526\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.3953 - acc: 0.8235 - val_loss: 0.4915 - val_acc: 0.7538\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.3731 - acc: 0.8359 - val_loss: 0.4937 - val_acc: 0.7572\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.3529 - acc: 0.8474 - val_loss: 0.4982 - val_acc: 0.7560\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.3343 - acc: 0.8596 - val_loss: 0.5036 - val_acc: 0.7528\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 35us/step - loss: 0.3158 - acc: 0.8699 - val_loss: 0.5093 - val_acc: 0.7518\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.2983 - acc: 0.8796 - val_loss: 0.5172 - val_acc: 0.7490\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length = maxlen))   # 나중에 임베딩된 입력을 Flatten층에서 펼치기 위해 Embedding층에input_length를 지정합니다. Embedding층의 출력크기는 (samples, maxlen, 8)이 됩니다.\n",
    "\n",
    "model.add(Flatten())                                    # 3D 임베딩 텐서를 (samples, maxlen * 8) 크기의 2D 텐서로 펼칩니다.\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))             # 분류기를 추가합니다.\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 10, batch_size = 32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 훈련된 단어 임베딩 사용하기\n",
    "\n",
    "훈련데이터가 부족하면 작업에 맞는 당너 임베딩을 학습할 수 없습니다. 이때는 풀려는 문제와 함께 임베딩을 학습한느 대신에 미리 계산된 임베딩 공간에서 임베딩 벡터를 로드할 수 있습니다. 이런 임베딩 공간은 **뛰어난 구조와 유용한 성질을 가지고 있어 언어 구조의 일반적인 측면을 잡아낼 수 있습니다.**  자연어 처리에서 사전 훈련된 단어 임베딩을 사용하는 이유는 이미지 분류 문제에서 사전 훈련된 컨브넷을 사용하는 이유와 거의 동일합니다. 충분한 데이터가 없어서 자신만의 좋은 특성을 학습하지 못하지만 꽤 일반적인 특성이 필요할 때입니다. 이런 경우에는 다른 문제에서 학습한 특성을 재사용하는 것이 합리적입니다.\n",
    "\n",
    "단어 임베딩은 일반적으로 단어 출현 통계를 사용하여 계산됩니다. 여기에는 신경망을 사용하는 기법도, 아닌 기법도 있습니다. **word2vec**은 가장 유명하고 성공한 단어 임베딩 방법입니다. Word2vec의 차원은 성별처럼 구체적인 의미가 있는 속성을 잡아냅니다.\n",
    "\n",
    "인기있는 또 다른 하나는 **GloVe**입니다. 이 임베딩 기법은 단어의 동시 출현 통계를 기록한 행렬을 분해하는 기법을 사용하빈다. 이 개발자들은 위키피디아 데이터와 커먼 크롤 데이터에서 가져온 수백만개의 영어 토큰에 대해서 임베딩을 미리 계산해놓았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir  = './datasets/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "labels    = []     # 긍정 또는 부정 \n",
    "texts     = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding = 'utf8')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88582개의 고유한 토큰을 찾았습니다.\n",
      "데이터 텐서의 크기 : (25000, 100)\n",
      "레이블 텐서의 크기 : (25000,)\n"
     ]
    }
   ],
   "source": [
    "### tokenize data\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "maxlen             = 100     # 100개 단어 이후는 버립니다.\n",
    "training_samples   = 200     # 훈련 샘플은 200개입니다.\n",
    "validation_samples = 10000   # 검증 샘플은 1만개입니다.\n",
    "max_words          = 10000   # 데이터셋에서 가장 빈도 높은 1만개의 단어만 사용합니다.\n",
    "\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('%s개의 고유한 토큰을 찾았습니다.' % len(word_index))\n",
    "\n",
    "data    = pad_sequences(sequences, maxlen = maxlen)\n",
    "labels  = np.asarray(labels)\n",
    "print('데이터 텐서의 크기 :', data.shape )\n",
    "print('레이블 텐서의 크기 :', labels.shape )\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data    = data[indices]\n",
    "labels  = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val   = data[training_samples:   training_samples + validation_samples]\n",
    "y_val   = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_dir = './datasets/'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), encoding = 'utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word   = values[0]\n",
    "    coefs  = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] =coefs\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7f8e5ea98c18>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length = maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(1,  activation = 'sigmoid'))\n",
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.1531 - acc: 0.4800 - val_loss: 0.6929 - val_acc: 0.5086\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6413 - acc: 0.6450 - val_loss: 0.7114 - val_acc: 0.5127\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5153 - acc: 0.8200 - val_loss: 1.0803 - val_acc: 0.5020\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5224 - acc: 0.7600 - val_loss: 0.6835 - val_acc: 0.5651\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3390 - acc: 0.9300 - val_loss: 0.6892 - val_acc: 0.5489\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.2809 - acc: 0.9950 - val_loss: 0.8081 - val_acc: 0.5073\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3162 - acc: 0.8700 - val_loss: 0.7185 - val_acc: 0.5594\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1624 - acc: 0.9800 - val_loss: 0.8836 - val_acc: 0.5038\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1684 - acc: 0.9650 - val_loss: 0.9035 - val_acc: 0.5207\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1006 - acc: 0.9900 - val_loss: 0.7137 - val_acc: 0.5691\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "history = model.fit(x_train, y_train, epochs = 10, batch_size  =32, validation_data = (x_val, y_val))\n",
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8eac259b00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc      = history.history['acc']\n",
    "val_acc  = history.history['val_acc']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc,      'bo', label = 'Training_acc')\n",
    "plt.plot(epochs, val_acc,  'b',  label = 'Validation_acc')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss,     'bo', label = 'Training_loss')\n",
    "plt.plot(epochs, val_loss, 'b',  label = 'Validation_loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 과대적합이 빠르게 시작됩니다. 훈련 샘플 수가 작기 때문에 놀라운 일은 아닙니다. 같은 이유로 검증 정확도와 훈련 정확도 사이에 차이가 큽니다. 검증 정확도는 50% 후반을 달성한 것 같습니다. 훈련 샘플 수가 적기 때문에 어떤 샘플 200개를 선택했는 지에 따라 성능이 크게 좌우됩니다. 여기서는 샘플들을 랜덤하게 선택했습니다. 선택한 샘플에서 성능이 나쁘면 예제를 위해서 랜덤하게 200개의 샘플을 다시 추출하면 됩니다. (실전에서는 훈련데이터를 고르지는 않습니다.)\n",
    "\n",
    "사전 훈련된 단어 임베딩을 사용하지 않거나 임베딩 층을 동결하지 않고 같은 모델을 훈련할 수 있습니다. 이런 경우 해당 작업에 특화된 입력 토큰의 임베딩을 학습할 것입니다. 데이터가 풍부하게 있다면 사전 훈련된 단어 임베딩보다 일반적으로 훨씬 성능이 높습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6924 - acc: 0.5600 - val_loss: 0.6925 - val_acc: 0.5217\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5010 - acc: 0.9700 - val_loss: 0.7029 - val_acc: 0.5220\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2827 - acc: 0.9750 - val_loss: 0.6974 - val_acc: 0.5171\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1247 - acc: 1.0000 - val_loss: 0.7015 - val_acc: 0.5235\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0607 - acc: 1.0000 - val_loss: 0.7102 - val_acc: 0.5248\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.7118 - val_acc: 0.5261\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.7124 - val_acc: 0.5309\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7184 - val_acc: 0.5306\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7247 - val_acc: 0.5310\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.7301 - val_acc: 0.5303\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_words, embedding_dim, input_length = maxlen))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(32, activation = 'relu'))\n",
    "model2.add(Dense(1,  activation = 'sigmoid'))\n",
    "model2.summary\n",
    "\n",
    "model2.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "history = model2.fit(x_train, y_train, epochs = 10, batch_size  =32, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**적은 수의 훈련 샘플로 작업하는 것은 어려운 일입니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
